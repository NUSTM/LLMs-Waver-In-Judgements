# Ask Again, Then Fail: Large Language Models' Vacillations in Judgement

<i>Qiming Xie, Zengzhi Wang, Yi Feng, Rui Xia</i>

<i>Nanjing University of Science and Technology, China</i>


 üìÑ [[Paper]](https://arxiv.org/abs/2310.02174) &nbsp; üñ•Ô∏è [[Homepage on PaperWithCode]](https://paperswithcode.com/paper/ask-again-then-fail-large-language-models)


 ## Quick links

  - [Overview](#overview)
  - [Follow-up Questioning Mechanism](#follow-up-questioning-mechanism)
  - [Evaluation](#evaluation)
    - [Experimental Setup](#experimental-setup)
    - [Results Analysis](#results-analysis)
  - [Further Studies](#further-studies)
    - [The Impact of Sampling Temperature](#the-impact-of-sampling-temperature)
    - [The Impact of Different Prompts](#the-impact-of-different-propmts)
    - [Error Analysis](#error-analysis)
    - [Can the Mechanism Correct Models?](can-the-mechanism-correct-models)
  - [Case Study](#case-study)
  - [Any Question?](#any-questions)
  - [Citation](#citation)


## Overview


## Follow-up Questioning Mechanism


## Evaluation


### Experimental Setup


### Results Analysis


## Further Studies


### The Impact of Sampling Temperature


### The Impact of Different Prompts


### Error Analysis


### Can the Mechanism Correct Models?


## Case Study


## Citation

If you find this work helpful, please cite our paper as follows:

```
xxx
```


## Any Questions?

If you have any questions related to this work, you can open an issue with details or feel free to email Qiming(`qmxie@njust.edu.cn`), Zengzhi(`zzwang@njust.edu.cn`).
